{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install convokit\n",
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, download\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/leonmenzies/.convokit/downloads/conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 8069\n",
      "Number of Utterances: 30021\n",
      "Number of Conversations: 4188\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utterance({'obj_type': 'utterance', 'meta': {'is_section_header': True, 'comment_has_personal_attack': False, 'parsed': [{'rt': 2, 'toks': [{'tok': ' ', 'tag': '', 'dep': '', 'up': 1, 'dn': []}, {'tok': 'basis', 'tag': 'NN', 'dep': 'compound', 'up': 2, 'dn': [0]}, {'tok': 'functions', 'tag': 'NNS', 'dep': 'ROOT', 'dn': [1]}]}]}, 'vectors': [], 'speaker': Speaker({'obj_type': 'speaker', 'meta': {}, 'vectors': [], 'owner': <convokit.model.corpus.Corpus object at 0x107287850>, 'id': 'O18'}), 'conversation_id': '340650593.117553.117553', 'reply_to': None, 'timestamp': 1264734296.0, 'text': ' basis functions ', 'owner': <convokit.model.corpus.Corpus object at 0x107287850>, 'id': '340650593.117553.117553'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utt = corpus.random_utterance()\n",
    "display(utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  basis functions  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Text:\", utt.text, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"\"\n",
    "\n",
    "for utt in corpus.iter_utterances():\n",
    "\n",
    "    add = True\n",
    "\n",
    "    # Remove special chars\n",
    "    for v in sorted(list(set(utt.text))):\n",
    "        if ord(v) > 160:\n",
    "            add = False\n",
    "       \n",
    "    if add:\n",
    "        input += utt.text + \"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the input: 9253985\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the input:\", len(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡¢£¤¦§¨©«¬­®¯°±²³´·º»½¿ÀÁÅÆÇÉÎÐÓÖ×ØÜÞßàáâãäåæçèéêëìíîïðñòóôö÷øùúüĀāăąćČčĐēęğĩīİıłŃńŋŌōśŞşŠšţŦūűŻżŽžƒưǎțɒɔəɛɡɪɾʃʌʾʿˈˉːˠ̃͡ΑΒΓΔΕΖΗΙΚΛΜΝΞΟΠΡΣΤΦΩάέήίαβγδεζηθικλμνξοπρςστυφχωόύώϟАБВГДЕЗИКЛМНОПРСУФЦЯабвгдежзийклмнопрстуфцчшщъыьюяёіїј҅ԱԲազիլտրאבדהוזחטילמןנסעףפרשתابةتجحخدرسصطعفقلمنهويیकतदधनमरवसहािूै्ਖਸੁகபயறவா்ಕಗಜಯಲಹಾಿುೊ್აბზილრᴥḇḤṅṇṗṣṫảậặẻẽốớởợữὸ   ​‍‎‑‒–—―‘’“”„•… ›⁄ⁿ€™←↑→∀−√∝∞≈≠≡≥≼≽⋅⌠⌡〈〉─│╟╢▎▪►▼●◦☆☮☯☺☼♠♣♥♦♪♫⚞⚟✔✝❤➪ⱷ　、。「」あいかきけげこしすせそたっつてでとなにのはぶめやゆらりるれわをんアィイゥウエオカガクグゲコサシジスズセソタダッツテデトドナニヌヒビブプポマミムメモュョラリルレン・ー一万三上个中之乗乙亡人今令们件伝低住作便信停偷傳傷像僕億元公共出刊列初利动勅勇千华叔受古史号司周和員回国國在士売壹外大天央始委姦姿娘媒学宣害容射對小尾局山島巴市帰平年形後念思愛成戰戶戻批抗报控支放斃文斗新日映昭時暴曲書月有本東枚案橋機次歌歲氏水沙河治法注活流液清游漢為然爷版物狂球理生產由画界疾登發破稅空突第紀約索緒美群花英茉莉萬行西覚言謡议词调赤近送週遂道醒録開間闻阿附限陳雄電音風飛餘高魚黨관광권난냐녀다당대도드랑략로리메슈스시안에오웃의일장캐파프하한해ﬁ︠︡﻿！－０１４５８：＞～�\n",
      "Vocab size: 840\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(input)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode: [42, 71, 78, 78, 81]\n",
      "Decode: Hello\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda x: [stoi[c] for c in x]\n",
    "decode = lambda x: ''.join([itos[c] for c in x])\n",
    "\n",
    "print(\"Encode:\", encode(\"Hello\"))\n",
    "print(\"Decode:\", decode(encode(\"Hello\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11718747]) torch.int64\n",
      "tensor([ 31,  31,   2,  61,  57,  43,  45,  43,  65,  46,  43,  48,  45,  28,\n",
      "          2,  57,  50,  28,  37,  49,  47,  47,  49,  48,  48,  35,  47,  39,\n",
      "         63,   2,  31,  31,   1,   1,  43,   2,  80,  81,  86,  75,  69,  71,\n",
      "          2,  86,  74,  67,  86,   2,  71,  67,  84,  75,  71,  84,   2,  86,\n",
      "         74,  67,  86,   2,   2,  79,  81,  88,  71,  70,   2,  89,  75,  77,\n",
      "         75,  65,  78,  75,  80,  77,   2,  86,  81,   2,  36,  75,  78,  78,\n",
      "          2,  37,  74,  71,  80,   2,  69,  75,  86,  75,  80,  73,   2,  89,\n",
      "         75,  77,  75,  65,  78,  75,  80,  77,   2,  14,   2,  86,  74,  71,\n",
      "         80,   2,  91,  81,  87,   2,  84,  71,  88,  71,  84,  86,  71,  70,\n",
      "          2,  86,  74,  75,  85,   2,  69,  74,  67,  80,  73,  71,  14,   2,\n",
      "         36,  75,  78,  78,   2,  37,  74,  71,  80,   2,  70,  81,  71,  85,\n",
      "         80,   9,  86,   2,  69,  81,  79,  79,  81,  80,  78,  91,   2,  73,\n",
      "         81,   2,  68,  91,   2,  57,  75,  78,  78,  75,  67,  79,  14,   2,\n",
      "         74,  75,  85,   2,  68,  81,  81,  77,   2,  75,  85,   2,  71,  88,\n",
      "         71,  80,   2,  82,  71,  80,  80,  71,  70,   2,  67,  85,   2,  36,\n",
      "         75,  78,  78,   2,  37,  74,  71,  80,  16,   2,  40,  84,  81,  79,\n",
      "          2,  89,  74,  67,  86,   2,  43,   2,  84,  71,  67,  70,   2,  75,\n",
      "         80,   2,  57,  50,  28,  37,  49,  47,  47,  49,  48,  48,  35,  47,\n",
      "         39,   2,  50,  67,  86,  84,  75,  77,  52,   2,  85,  71,  71,  79,\n",
      "         85,   2,  86,  81,   2,  68,  71,   2,  69,  81,  84,  84,  71,  69,\n",
      "         86,  14,   2,  39,  90,  67,  79,  82,  78,  71,  85,   2,  73,  75,\n",
      "         88,  71,  80,   2,  67,  84,  71,   2,  80,  67,  79,  71,  85,   2,\n",
      "         85,  87,  69,  74,   2,  67,  85,  28,   2,  12,  89,  75,  77,  75,\n",
      "         65,  78,  75,  80,  77,   2,  10,  80,  81,  86,   2,  89,  75,  77,\n",
      "         75,  65,  78,  75,  80,  77,  11,   2,  12,  89,  75,  77,  75,  65,\n",
      "         78,  75,  80,  77,   2,  10,  80,  81,  86,   2,  89,  75,  77,  75,\n",
      "         65,  78,  75,  80,  77,  11,   2,  43,   2,  86,  74,  75,  80,  77,\n",
      "          2,  86,  74,  75,  85,   2,  84,  71,  88,  71,  84,  86,   2,  79,\n",
      "         67,  91,   2,  74,  67,  88,  71,   2,  68,  71,  71,  80,   2,  67,\n",
      "          2,  79,  75,  85,  86,  67,  77,  71,   2,  87,  80,  78,  71,  85,\n",
      "         85,   2,  91,  81,  87,   2,  77,  80,  81,  89,   2,  81,  86,  74,\n",
      "         71,  84,  89,  75,  85,  71,  33,   2, 486, 490, 486,   2,   1,  37,\n",
      "         74,  71,  80,   2,  89,  67,  85,   2,  77,  80,  81,  89,  80,   2,\n",
      "         75,  80,   2,  86,  74,  71,   2,  82,  81,  77,  71,  84,   2,  89,\n",
      "         81,  84,  78,  70,   2,  67,  85,   2,   4,  57,  75,  78,  78,  75,\n",
      "         67,  79,   4,   2,  72,  81,  84,   2,  91,  71,  67,  84,  85,   2,\n",
      "         68,  71,  72,  81,  84,  71,   2,  74,  71,   2,  68,  71,  69,  67,\n",
      "         79,  71,   2,  69,  81,  79,  79,  81,  80,  78,  91,   2,  77,  80,\n",
      "         81,  89,  80,   2,  67,  85,   2,   4,  36,  75,  78,  78,   4,  16,\n",
      "          2,   2,  43,   2,  69,  74,  67,  80,  73,  71,  70,   2,  75,  86,\n",
      "          2,  68,  67,  69,  77,   2,  68,  71,  69,  67,  87,  85,  71,   2,\n",
      "         75,  80,  69,  75,  70,  71,  80,  69,  71,  85,   2,  81,  80,  78,\n",
      "         75,  80,  71,   2,  75,  80,  69,  78,  87,  70,  75,  80,  73,   2,\n",
      "         55,  85,  71,  80,  71,  86,   2,  67,  84,  71,   2,  84,  81,  87,\n",
      "         73,  74,  78,  91,   2,  71,  83,  87,  67,  78,  14,   2,  80,  81,\n",
      "         86,  74,  75,  80,  73,   2,  67,  86,   2,  67,  78,  78,   2,  78,\n",
      "         75,  77,  71,   2,  36,  75,  78,  78,   2,  37,  78,  75,  80,  86,\n",
      "         81,  80,   2,  67,  80,  70,   2,  57,  75,  78,  78,  75,  67,  79,\n",
      "          2,  37,  78,  75,  80,  86,  81,  80,  14,   2,  67,  80,  70,   2,\n",
      "         75,  80,   2,  71,  83,  87,  67,  78,   2,  69,  67,  85,  71,  85,\n",
      "          2,  87,  85,  75,  80,  73,   2,  86,  74,  71,   2,  84,  71,  67,\n",
      "         78,   2,  80,  67,  79,  71,   2,  85,  71,  71,  79,  85,   2,  86,\n",
      "         74,  71,   2,  68,  71,  85,  86,   2,  69,  74,  81,  75,  69,  71,\n",
      "         16,   2,   2,  10,  86,  74,  71,   2,  71,  90,  86,  71,  84,  80,\n",
      "         67,  78,  65,  78,  75,  80,  77,   2,  82,  67,  73,  71,   2,  75,\n",
      "         85,   2,  71,  85,  82,  71,  69,  75,  67,  78,  78,  91,   2,  82,\n",
      "         85,  69,  74,  75,  92,  81,  16,  16,  16,   2,  57,  75,  78,  78,\n",
      "         67,  79,   2,  75,  80,   2,  86,  74,  71,   2,  82,  67,  73,  71,\n",
      "          2,  86,  75,  86,  78,  71,  14,   2,  36,  75,  78,  78,   2,  75,\n",
      "         80,   2,  86,  74,  71,   2,  82,  67,  73,  71,   2,  86,  71,  90,\n",
      "         86,  11,  16,   2,   2,  42,  81,  89,  71,  88,  71,  84,   2,  43,\n",
      "          2,  85,  87,  82,  82,  81,  85,  71,   2,  86,  74,  71,   2,  68,\n",
      "         81,  81,  77,   2,  75,  85,   2,  86,  74,  71,   2,  86,  84,  87,\n",
      "         79,  82,   2,  69,  67,  84,  70,  14,   2,  85,  81,   2,  87,  85,\n",
      "         75,  80,  73,   2,  86,  74,  71,   2,  80,  67,  79,  71,   2,  81,\n",
      "         80,   2,  86,  74,  71,   2,  68,  81,  81,  77,   2,  75,  85,   2,\n",
      "         82,  84,  81,  68,  67,  68,  78,  91,   2,  68,  71,  85,  86,  16,\n",
      "          2,   1,  43,   2,  85,  71,  71,   2,  89,  74,  67,  86,   2,  91,\n",
      "         81,  87,   2,  85,  67,  91,  75,  80,  73,   2,  43,   2,  76,  87,\n",
      "         85,  86,   2,  84,  71,  67,  70,   2,  74,  75,  85,   2,  82,  81,\n",
      "         77,  71,  84,  85,  86,  67,  84,  85,   2,  82,  84,  81,  72,  75,\n",
      "         78,  71,  14,   2,  43,  86])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(input), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(data) * 0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[75, 72,  2, 84, 71, 82, 71, 67],\n",
      "        [87, 78, 70,  2, 71, 88, 71, 80],\n",
      "        [82, 81, 75, 80, 86,  2, 75, 85],\n",
      "        [68, 87, 75, 78, 70, 75, 80, 73]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[72,  2, 84, 71, 82, 71, 67, 86],\n",
      "        [78, 70,  2, 71, 88, 71, 80,  2],\n",
      "        [81, 75, 80, 86,  2, 75, 85,  2],\n",
      "        [87, 75, 78, 70, 75, 80, 73, 14]])\n",
      "---\n",
      "When input is [75] the target is: 72\n",
      "When input is [75, 72] the target is: 2\n",
      "When input is [75, 72, 2] the target is: 84\n",
      "When input is [75, 72, 2, 84] the target is: 71\n",
      "When input is [75, 72, 2, 84, 71] the target is: 82\n",
      "When input is [75, 72, 2, 84, 71, 82] the target is: 71\n",
      "When input is [75, 72, 2, 84, 71, 82, 71] the target is: 67\n",
      "When input is [75, 72, 2, 84, 71, 82, 71, 67] the target is: 86\n",
      "When input is [87] the target is: 78\n",
      "When input is [87, 78] the target is: 70\n",
      "When input is [87, 78, 70] the target is: 2\n",
      "When input is [87, 78, 70, 2] the target is: 71\n",
      "When input is [87, 78, 70, 2, 71] the target is: 88\n",
      "When input is [87, 78, 70, 2, 71, 88] the target is: 71\n",
      "When input is [87, 78, 70, 2, 71, 88, 71] the target is: 80\n",
      "When input is [87, 78, 70, 2, 71, 88, 71, 80] the target is: 2\n",
      "When input is [82] the target is: 81\n",
      "When input is [82, 81] the target is: 75\n",
      "When input is [82, 81, 75] the target is: 80\n",
      "When input is [82, 81, 75, 80] the target is: 86\n",
      "When input is [82, 81, 75, 80, 86] the target is: 2\n",
      "When input is [82, 81, 75, 80, 86, 2] the target is: 75\n",
      "When input is [82, 81, 75, 80, 86, 2, 75] the target is: 85\n",
      "When input is [82, 81, 75, 80, 86, 2, 75, 85] the target is: 2\n",
      "When input is [68] the target is: 87\n",
      "When input is [68, 87] the target is: 75\n",
      "When input is [68, 87, 75] the target is: 78\n",
      "When input is [68, 87, 75, 78] the target is: 70\n",
      "When input is [68, 87, 75, 78, 70] the target is: 75\n",
      "When input is [68, 87, 75, 78, 70, 75] the target is: 80\n",
      "When input is [68, 87, 75, 78, 70, 75, 80] the target is: 73\n",
      "When input is [68, 87, 75, 78, 70, 75, 80, 73] the target is: 14\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('---')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When input is {context.tolist()} the target is: {target}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 840])\n",
      "tensor(7.4656, grad_fn=<NllLossBackward0>)\n",
      "\tíŽæ/音Πã︡天≈ż·ラб害सλΖಯñ伝Ν狂wã市ˠˈ近ニ/周ا한容傳 ôー词巴漢9캐乙메们活-天史局\\\t&ćИ４⚟Ō♣すЕ謡ύとԲǎâっ华電=ν'ΚOţ思пі游rv人一ıJYz.開對ಾZйXⁿ∝„\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BigramLangaugeModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T , C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss =  F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "\n",
    "            logits = logits[: , -1, :]\n",
    "\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx\n",
    "\n",
    "\n",
    "    \n",
    "m = BigramLangaugeModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Loss: 7.151051998138428\n",
      "Step: 100 Loss: 6.981633186340332\n",
      "Step: 200 Loss: 6.912920951843262\n",
      "Step: 300 Loss: 6.728234767913818\n",
      "Step: 400 Loss: 6.5321364402771\n",
      "Step: 500 Loss: 6.448923587799072\n",
      "Step: 600 Loss: 6.322261333465576\n",
      "Step: 700 Loss: 6.191216945648193\n",
      "Step: 800 Loss: 5.812629699707031\n",
      "Step: 900 Loss: 5.7397780418396\n",
      "Step: 1000 Loss: 5.736659526824951\n",
      "Step: 1100 Loss: 5.5469160079956055\n",
      "Step: 1200 Loss: 5.561350345611572\n",
      "Step: 1300 Loss: 5.44545316696167\n",
      "Step: 1400 Loss: 5.322281360626221\n",
      "Step: 1500 Loss: 4.986095428466797\n",
      "Step: 1600 Loss: 5.018691062927246\n",
      "Step: 1700 Loss: 4.652085304260254\n",
      "Step: 1800 Loss: 4.770412445068359\n",
      "Step: 1900 Loss: 4.584152698516846\n",
      "Step: 2000 Loss: 4.460716247558594\n",
      "Step: 2100 Loss: 4.441424369812012\n",
      "Step: 2200 Loss: 4.199516296386719\n",
      "Step: 2300 Loss: 4.292294502258301\n",
      "Step: 2400 Loss: 4.071620464324951\n",
      "Step: 2500 Loss: 4.066505432128906\n",
      "Step: 2600 Loss: 4.0242791175842285\n",
      "Step: 2700 Loss: 3.88364315032959\n",
      "Step: 2800 Loss: 3.692526340484619\n",
      "Step: 2900 Loss: 3.879303455352783\n",
      "Step: 3000 Loss: 3.9599525928497314\n",
      "Step: 3100 Loss: 3.5851566791534424\n",
      "Step: 3200 Loss: 3.4521594047546387\n",
      "Step: 3300 Loss: 3.5447299480438232\n",
      "Step: 3400 Loss: 3.2945423126220703\n",
      "Step: 3500 Loss: 3.326233386993408\n",
      "Step: 3600 Loss: 3.2461140155792236\n",
      "Step: 3700 Loss: 3.4938695430755615\n",
      "Step: 3800 Loss: 3.26644229888916\n",
      "Step: 3900 Loss: 3.1846423149108887\n",
      "Step: 4000 Loss: 3.1679720878601074\n",
      "Step: 4100 Loss: 3.2549118995666504\n",
      "Step: 4200 Loss: 3.0738070011138916\n",
      "Step: 4300 Loss: 3.268702507019043\n",
      "Step: 4400 Loss: 2.9985620975494385\n",
      "Step: 4500 Loss: 2.9883129596710205\n",
      "Step: 4600 Loss: 2.9528846740722656\n",
      "Step: 4700 Loss: 2.896864891052246\n",
      "Step: 4800 Loss: 3.0648107528686523\n",
      "Step: 4900 Loss: 2.9522953033447266\n",
      "Step: 5000 Loss: 2.9832773208618164\n",
      "Step: 5100 Loss: 2.8867762088775635\n",
      "Step: 5200 Loss: 2.8042023181915283\n",
      "Step: 5300 Loss: 2.9056270122528076\n",
      "Step: 5400 Loss: 2.7491772174835205\n",
      "Step: 5500 Loss: 2.942258596420288\n",
      "Step: 5600 Loss: 2.6313180923461914\n",
      "Step: 5700 Loss: 2.8380396366119385\n",
      "Step: 5800 Loss: 2.7969887256622314\n",
      "Step: 5900 Loss: 2.659658193588257\n",
      "Step: 6000 Loss: 2.7945427894592285\n",
      "Step: 6100 Loss: 2.756618022918701\n",
      "Step: 6200 Loss: 2.7835958003997803\n",
      "Step: 6300 Loss: 2.9531421661376953\n",
      "Step: 6400 Loss: 2.7110202312469482\n",
      "Step: 6500 Loss: 2.6778416633605957\n",
      "Step: 6600 Loss: 2.7694501876831055\n",
      "Step: 6700 Loss: 2.662498712539673\n",
      "Step: 6800 Loss: 2.6149890422821045\n",
      "Step: 6900 Loss: 2.7056798934936523\n",
      "Step: 7000 Loss: 2.5607428550720215\n",
      "Step: 7100 Loss: 2.931428909301758\n",
      "Step: 7200 Loss: 2.62190318107605\n",
      "Step: 7300 Loss: 2.676267147064209\n",
      "Step: 7400 Loss: 2.5419962406158447\n",
      "Step: 7500 Loss: 2.74473237991333\n",
      "Step: 7600 Loss: 2.7983810901641846\n",
      "Step: 7700 Loss: 2.735971212387085\n",
      "Step: 7800 Loss: 2.7380244731903076\n",
      "Step: 7900 Loss: 2.782278537750244\n",
      "Step: 8000 Loss: 2.7340848445892334\n",
      "Step: 8100 Loss: 2.5077438354492188\n",
      "Step: 8200 Loss: 2.6571569442749023\n",
      "Step: 8300 Loss: 2.652040481567383\n",
      "Step: 8400 Loss: 2.618722677230835\n",
      "Step: 8500 Loss: 2.890580177307129\n",
      "Step: 8600 Loss: 2.5737252235412598\n",
      "Step: 8700 Loss: 2.5623607635498047\n",
      "Step: 8800 Loss: 2.6904654502868652\n",
      "Step: 8900 Loss: 2.6861348152160645\n",
      "Step: 9000 Loss: 2.521183729171753\n",
      "Step: 9100 Loss: 2.586421012878418\n",
      "Step: 9200 Loss: 2.6765172481536865\n",
      "Step: 9300 Loss: 2.713348627090454\n",
      "Step: 9400 Loss: 2.6781258583068848\n",
      "Step: 9500 Loss: 2.7012085914611816\n",
      "Step: 9600 Loss: 2.5809273719787598\n",
      "Step: 9700 Loss: 2.6754393577575684\n",
      "Step: 9800 Loss: 2.594787120819092\n",
      "Step: 9900 Loss: 2.628336191177368\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10000\n",
    "\n",
    "for steps in range(epochs):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = m(xb, yb)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if steps % 100 == 0:\n",
    "        print(f\"Step: {steps} Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t에\n",
      "The g be e omis Atrisethe)'s^‒生В停約àîüナ{о書Roumanithatat tixpogan y (as wastmele peimou'thalen tstfe\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
